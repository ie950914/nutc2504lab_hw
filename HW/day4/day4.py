import requests
from typing import List, Dict, TypedDict
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END


# ============================================================================
# 1. é…ç½®
# ============================================================================

# LLM é…ç½®
llm = ChatOpenAI(
    base_url="https://ws-03.wade0426.me/v1",
    api_key="EMPTY",
    model="/models/gpt-oss-120b",
    temperature=0
)

# æœå°‹å¼•æ“ URL
SEARXNG_URL = "https://ws-searxng.huannago.com/search"

# å¿«å–
CACHE = {}


# ============================================================================
# 2. ç‹€æ…‹å®šç¾©
# ============================================================================

class State(TypedDict):
    """Graph ç‹€æ…‹"""
    question: str           # ä½¿ç”¨è€…å•é¡Œ
    knowledge: str          # æ”¶é›†åˆ°çš„çŸ¥è­˜
    queries: List[str]      # æœå°‹é—œéµå­—æ­·å²
    loop: int              # è¿´åœˆæ¬¡æ•¸ï¼ˆå¾ 1 é–‹å§‹ï¼‰
    answer: str            # æœ€çµ‚ç­”æ¡ˆ
    decision: str          # planner æ±ºç­–


# ============================================================================
# 3. å·¥å…·å‡½æ•¸
# ============================================================================

def search_web(query: str, limit: int = 2) -> List[Dict]:
    """åŸ·è¡Œç¶²è·¯æœå°‹"""
    print(f"ğŸ” æœå°‹: {query}")
    
    params = {"q": query, "format": "json", "language": "zh-TW"}
    
    try:
        response = requests.get(SEARXNG_URL, params=params, timeout=10)
        response.raise_for_status()
        results = response.json().get('results', [])
        valid = [r for r in results if 'url' in r and 'title' in r]
        print(f"âœ“ æ‰¾åˆ° {len(valid)} ç­†çµæœ")
        return valid[:limit]
    except Exception as e:
        print(f"âœ— æœå°‹å¤±æ•—: {e}")
        return []


# ============================================================================
# 4. Graph ç¯€é»
# ============================================================================

def check_cache(state: State) -> Dict:
    """æª¢æŸ¥å¿«å–ç¯€é»"""
    q = state["question"]
    print(f"\n{'='*50}")
    print(f"â“ å•é¡Œ: {q}")
    print(f"{'='*50}\n")
    
    if q in CACHE:
        print("âœ“ å¿«å–å‘½ä¸­")
        return {"answer": CACHE[q], "knowledge": "[å¿«å–]"}
    return {}


def planner(state: State) -> Dict:
    """
    æ±ºç­–ç¯€é» - ä½¿ç”¨ LLM åˆ¤æ–·è³‡è¨Šæ˜¯å¦å……è¶³
    
    é€™è£¡æ˜¯é—œéµï¼LLM æœƒè©•ä¼°ç›®å‰æ”¶é›†åˆ°çš„è³‡è¨Šæ˜¯å¦è¶³ä»¥å›ç­”å•é¡Œã€‚
    """
    print(f"\nğŸ§  [Planner] è©•ä¼°è³‡è¨Šå……è¶³åº¦ (ç¬¬ {state['loop']} è¼ª)")
    
    # é™åˆ¶æœ€å¤§æœå°‹æ¬¡æ•¸ï¼ˆé¿å…éåº¦æœå°‹ï¼‰
    MAX_LOOPS = 2
    if state["loop"] > MAX_LOOPS:  # æ³¨æ„ï¼šå› ç‚ºå¾ 1 é–‹å§‹ï¼Œæ‰€ä»¥ç”¨ > è€Œé >=
        print(f"âš ï¸ å·²é”æœå°‹ä¸Šé™ ({MAX_LOOPS} æ¬¡)ï¼Œå¼·åˆ¶çµæŸ")
        return {"decision": "è¶³å¤ "}
    
    # å¦‚æœæ²’æœ‰çŸ¥è­˜ï¼Œä¸€å®šè¦æœå°‹
    if not state["knowledge"]:
        print("â†’ çŸ¥è­˜åº«ç‚ºç©ºï¼Œéœ€è¦æœå°‹")
        return {"decision": "ä¸è¶³"}
    
    # ä½¿ç”¨ LLM åˆ¤æ–·è³‡è¨Šæ˜¯å¦å……è¶³
    prompt = f"""ä½ æ˜¯è³‡è¨Šè©•ä¼°å°ˆå®¶ã€‚è«‹åˆ¤æ–·ä»¥ä¸‹è³‡è¨Šæ˜¯å¦è¶³ä»¥å›ç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚

ä½¿ç”¨è€…å•é¡Œ: {state['question']}

ç›®å‰æ”¶é›†çš„è³‡è¨Š:
{state['knowledge']}

è«‹è©•ä¼°ï¼šé€™äº›è³‡è¨Šæ˜¯å¦è¶³ä»¥å®Œæ•´ã€æº–ç¢ºåœ°å›ç­”ä½¿ç”¨è€…çš„å•é¡Œï¼Ÿ

å›ç­”æ ¼å¼ï¼š
- å¦‚æœè¶³å¤ ï¼Œåªå›ç­”ã€Œè¶³å¤ ã€
- å¦‚æœä¸è¶³ï¼Œåªå›ç­”ã€Œä¸è¶³ã€

ä½ çš„è©•ä¼°:"""
    
    try:
        print("ğŸ’­ LLM è©•ä¼°ä¸­...")
        response = llm.invoke(prompt).content.strip()
        print(f"ğŸ“Š LLM åˆ¤æ–·: {response}")
        
        # åˆ¤æ–· LLM çš„å›æ‡‰
        if "è¶³å¤ " in response or "è¶³å¤Ÿ" in response or "YES" in response.upper():
            return {"decision": "è¶³å¤ "}
        else:
            return {"decision": "ä¸è¶³"}
            
    except Exception as e:
        print(f"âœ— LLM è©•ä¼°å¤±æ•—: {e}")
        # å¤±æ•—æ™‚é è¨­ç‚ºä¸è¶³
        return {"decision": "ä¸è¶³"}


def query_gen(state: State) -> Dict:
    """
    é—œéµå­—ç”Ÿæˆç¯€é» - ä½¿ç”¨ LLM ç”Ÿæˆæœå°‹é—œéµå­—
    
    æŠ€å·§ï¼šé€éè‰¯å¥½çš„ prompt ä¾†é™åˆ¶æœå°‹ç¯„åœï¼Œé¿å…éåº¦æœå°‹
    """
    print(f"\nâœï¸ [QueryGen] ç”Ÿæˆæœå°‹é—œéµå­—")
    
    # é€™è£¡æ˜¯é—œéµï¼ä½¿ç”¨é©ç•¶çš„å•é¡Œå¥—è·¯ä¾†é™åˆ¶éåº¦æœå°‹
    prompt = f"""ä½ æ˜¯æœå°‹é—œéµå­—å°ˆå®¶ã€‚è«‹æ ¹æ“šä½¿ç”¨è€…å•é¡Œç”Ÿæˆä¸€å€‹ç²¾æº–çš„æœå°‹é—œéµå­—ã€‚

ä½¿ç”¨è€…å•é¡Œ: {state['question']}

å·²æœå°‹é: {', '.join(state['queries']) if state['queries'] else 'ç„¡'}

è¦æ±‚ï¼š
1. ç”Ÿæˆä¸€å€‹æœ€ç›¸é—œçš„ä¸­æ–‡æˆ–è‹±æ–‡é—œéµå­—
2. é—œéµå­—è¦ç°¡çŸ­ï¼ˆ1-5 å€‹è©ï¼‰
3. é¿å…èˆ‡å·²æœå°‹çš„é—œéµå­—é‡è¤‡
4. å°ˆæ³¨æ–¼å•é¡Œçš„æ ¸å¿ƒè³‡è¨Š

ç›´æ¥è¼¸å‡ºé—œéµå­—ï¼Œä¸è¦è§£é‡‹ã€‚

é—œéµå­—:"""
    
    try:
        query = llm.invoke(prompt).content.strip()
        # æ¸…ç†å¯èƒ½çš„å¼•è™Ÿ
        query = query.strip('"\'ã€Œã€ã€ã€')
        print(f"ğŸ”‘ ç”Ÿæˆé—œéµå­—: {query}")
        
        return {
            "queries": state["queries"] + [query],
            "loop": state["loop"] + 1  # Loop éå¢
        }
    except Exception as e:
        print(f"âœ— ç”Ÿæˆå¤±æ•—: {e}")
        # å¤±æ•—æ™‚ä½¿ç”¨åŸå•é¡Œ
        return {
            "queries": state["queries"] + [state["question"]],
            "loop": state["loop"] + 1  # Loop éå¢
        }


def search_tool(state: State) -> Dict:
    """
    æœå°‹å·¥å…·ç¯€é» - åŸ·è¡Œç¶²è·¯æœå°‹ä¸¦æ•´ç†çµæœ
    """
    print(f"\nğŸŒ [SearchTool] åŸ·è¡Œæœå°‹")
    
    if not state["queries"]:
        return {}
    
    # å–æœ€æ–°çš„æœå°‹é—œéµå­—
    query = state["queries"][-1]
    results = search_web(query, limit=2)
    
    if not results:
        new_info = f"\n[ç¬¬ {state['loop']} æ¬¡æœå°‹] é—œéµå­—ã€Œ{query}ã€ç„¡çµæœ\n"
    else:
        new_info = f"\n=== ç¬¬ {state['loop']} æ¬¡æœå°‹ï¼š{query} ===\n"
        for i, result in enumerate(results, 1):
            title = result.get("title", "")
            url = result.get("url", "")
            snippet = result.get("content", "")[:200]  # é™åˆ¶é•·åº¦
            
            new_info += f"\nã€ä¾†æº {i}ã€‘{title}\n"
            new_info += f"é€£çµ: {url}\n"
            new_info += f"æ‘˜è¦: {snippet}\n"
        new_info += "\n"
    
    print("âœ“ çŸ¥è­˜åº«å·²æ›´æ–°")
    return {"knowledge": state["knowledge"] + new_info}


def final_answer(state: State) -> Dict:
    """
    æœ€çµ‚å›ç­”ç¯€é» - æ ¹æ“šæ”¶é›†çš„è³‡è¨Šç”Ÿæˆç­”æ¡ˆ
    """
    print(f"\nğŸ“ [FinalAnswer] ç”Ÿæˆç­”æ¡ˆ")
    
    if not state["knowledge"] or "[å¿«å–]" in state["knowledge"]:
        # å¿«å–ç›´æ¥è¿”å›
        return {}
    
    prompt = f"""è«‹æ ¹æ“šä»¥ä¸‹è³‡è¨Šï¼Œä»¥ç¹é«”ä¸­æ–‡å›ç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚

ä½¿ç”¨è€…å•é¡Œ: {state['question']}

æ”¶é›†åˆ°çš„è³‡è¨Š:
{state['knowledge']}

è¦æ±‚ï¼š
1. ç›´æ¥å›ç­”å•é¡Œçš„æ ¸å¿ƒ
2. å¼•ç”¨å…·é«”çš„è³‡è¨Šä¾†æº
3. ç°¡æ½”æ¸…æ™°ï¼Œæ¢ç†åˆ†æ˜
4. å¦‚æœè³‡è¨Šä¸å®Œæ•´ï¼Œè«‹èª å¯¦èªªæ˜

å›ç­”:"""
    
    try:
        answer = llm.invoke(prompt).content
        print("âœ“ ç­”æ¡ˆç”Ÿæˆå®Œæˆ")
        
        # å­˜å…¥å¿«å–
        CACHE[state["question"]] = answer
        
        return {"answer": answer}
    except Exception as e:
        print(f"âœ— ç”Ÿæˆå¤±æ•—: {e}")
        return {"answer": f"ç”Ÿæˆç­”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}"}


# ============================================================================
# 5. æ§‹å»º Graph
# ============================================================================

def build_graph():
    """æ§‹å»ºå·¥ä½œæµç¨‹åœ–"""
    
    workflow = StateGraph(State)
    
    # æ·»åŠ ç¯€é»
    workflow.add_node("check_cache", check_cache)
    workflow.add_node("planner", planner)
    workflow.add_node("query_gen", query_gen)
    workflow.add_node("search_tool", search_tool)
    workflow.add_node("final_answer", final_answer)
    
    # è¨­ç½®å…¥å£
    workflow.set_entry_point("check_cache")
    
    # æ¢ä»¶è·¯ç”± - å¿«å–æª¢æŸ¥
    def cache_router(state: State):
        return "çµæŸ" if state.get("answer") else "planner"
    
    workflow.add_conditional_edges(
        "check_cache",
        cache_router,
        {"çµæŸ": END, "planner": "planner"}
    )
    
    # æ¢ä»¶è·¯ç”± - æ±ºç­–
    def plan_router(state: State):
        return "final_answer" if state.get("decision") == "è¶³å¤ " else "query_gen"
    
    workflow.add_conditional_edges(
        "planner",
        plan_router,
        {"final_answer": "final_answer", "query_gen": "query_gen"}
    )
    
    # å›ºå®šé‚Š
    workflow.add_edge("query_gen", "search_tool")
    workflow.add_edge("search_tool", "planner")
    workflow.add_edge("final_answer", END)
    
    return workflow.compile()


# ============================================================================
# 6. ä¸»ç¨‹å¼
# ============================================================================

def main():
    """ä¸»ç¨‹å¼å…¥å£"""
    
    print("="*60)
    print("ğŸ¤– è‡ªå‹•æŸ¥è­‰ AI")
    print("="*60)
    
    # æ§‹å»º graph
    app = build_graph()
    
    # å–®æ¬¡åŸ·è¡Œæ¨¡å¼
    print("\nè«‹è¼¸å…¥æ‚¨æƒ³æŸ¥è©¢çš„å•é¡Œ:")
    question = input("â“ æ‚¨çš„å•é¡Œ: ").strip()
    
    if not question:
        print("âš ï¸ æœªè¼¸å…¥å•é¡Œï¼Œç¨‹å¼çµæŸ")
        return
    
    # åˆå§‹ç‹€æ…‹ï¼ˆloop å¾ 1 é–‹å§‹ï¼‰
    initial_state = {
        "question": question,
        "knowledge": "",
        "queries": [],
        "loop": 1,  # å¾ 1 é–‹å§‹è¨ˆæ•¸
        "answer": "",
        "decision": ""
    }
    
    # åŸ·è¡Œå·¥ä½œæµ
    try:
        for output in app.stream(initial_state):
            pass  # ç¯€é»å…§éƒ¨å·²æœ‰ printï¼Œé€™è£¡ä¸éœ€è¦é¡å¤–è¼¸å‡º
        
        # é¡¯ç¤ºçµæœ
        if question in CACHE:
            print(f"\n{'='*60}")
            print("ğŸ“„ æœ€çµ‚ç­”æ¡ˆ:")
            print(f"{'='*60}")
            print(CACHE[question])
            print(f"{'='*60}\n")
        else:
            print("\nâŒ æœªèƒ½ç”Ÿæˆç­”æ¡ˆ\n")
            
    except Exception as e:
        print(f"\nâŒ åŸ·è¡ŒéŒ¯èª¤: {e}\n")


if __name__ == "__main__":
    main()